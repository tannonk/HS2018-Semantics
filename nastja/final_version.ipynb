{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this script sets a baseline for relation extraction using frequency-based BOW model\n",
    "\n",
    "#### add additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# import networkx as nx\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 1. LOAD DATA ALTERED\n",
    "##################################################################################################\n",
    "\n",
    "PairExample = namedtuple('PairExample',\n",
    "    'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "    'left, mention_1, middle, mention_2, right, direction')\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i,line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "\n",
    "        instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "        \n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'],snippet['mention_1'],snippet['middle'],\n",
    "                                   snippet['mention_2'],snippet['right'],\n",
    "                                    snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "                \n",
    "                data.append(instance_tuple)\n",
    "                labels.append(instance['relation'])\n",
    "                instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "                \n",
    "            except:\n",
    "                print(instance)\n",
    "\n",
    "\n",
    "    return data,labels\n",
    "    \n",
    "train_data, train_labels = load_data('../data/train.json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics:\n",
      "                                rel_examples\n",
      "relation               examples /all_examples\n",
      "--------               --------    -------\n",
      "worked_at                  3669       0.09\n",
      "author                    13113       0.31\n",
      "NO_REL                     3068       0.07\n",
      "has_spouse                13061       0.31\n",
      "capital                    9427       0.22\n",
      "--------               --------    -------\n",
      "Total                     42338       1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check that each entity pair is assigned only one relation\n",
    "# pair_dict={}\n",
    "# rel_dict={}\n",
    "# for example, label in zip(train_data,train_labels):\n",
    "#     if (example.entity_1,example.entity_2) not in pair_dict.keys():\n",
    "#         pair_dict[(example.entity_1,example.entity_2)] = [label]\n",
    "        \n",
    "#     else:\n",
    "#         pair_dict[(example.entity_1,example.entity_2)].append(label)\n",
    "# #         print(example.entity_1,example.entity_2,label)\n",
    "#     if label not in rel_dict.keys():\n",
    "#         rel_dict[label] = [example]\n",
    "#     else:\n",
    "#         rel_dict[label].append(example)\n",
    "# print(\"Done building dictionary\")  \n",
    "    \n",
    "# # example for each relation\n",
    "# for rel in rel_dict.keys():\n",
    "#     ex = rel_dict[rel][0]\n",
    "#     print(rel,ex.entity_1,ex.entity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SelectContext(data, verbose=True):\n",
    "    \"\"\"BOW feature extraction\"\"\"\n",
    "    only_context_data = []\n",
    "    for instance in data:\n",
    "        \n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            instance_context.append(context)\n",
    "        only_context_data.append(' '.join(instance_context))\n",
    "    if verbose:\n",
    "        print(len(only_context_data))\n",
    "        print(only_context_data[0])\n",
    "        print(only_context_data[0])\n",
    "    return only_context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = SelectContext(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    \"\"\"Considers length and words of middle segment\"\"\"\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {'mid_words': '', 'distance': np.inf}\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = ExractSimpleFeatures(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LengthOfEntities(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'entity1_len': len(instance.entity_1.split(\"_\")),\n",
    "            'entity2_len': len(instance.entity_2.split(\"_\")),\n",
    "            'combined_len': len(instance.entity_1.split(\"_\")) + len(instance.entity_2.split(\"_\"))\n",
    "        }\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = LengthOfEntities(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UseNLP(data, verbose=True):\n",
    "    \"\"\"\n",
    "    Processes each data instance with Spacy's nlp pipeline \n",
    "    and collects POS tags for context window around mentions\n",
    "    as well as length of dependency path between two mentions\n",
    "    \"\"\"\n",
    "    featurized_data = []\n",
    "\n",
    "    for instance in data:\n",
    "        featurized_instance = {'tagged_context_1': '', 'tagged_context_2': '', 'path_length': 0}\n",
    "\n",
    "        for s in instance.snippet:\n",
    "            \n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            \n",
    "            document = nlp(context) # spacy pipeline\n",
    "            \n",
    "            tagged_context_1 = []\n",
    "            tagged_context_2 = []\n",
    "            \n",
    "            for i, w in enumerate(document):\n",
    "                if w.orth_ == \"m_1\":\n",
    "                    window_1 = document[i-3:i+4]\n",
    "                    for e in window_1:\n",
    "                        if e.orth_ == \"m_1\" or e.orth_ == \"m_2\":\n",
    "                            tagged_context_1.append(\"MENTION\")\n",
    "                        else:\n",
    "                            tagged_context_1.append(e.pos_)\n",
    "                \n",
    "                if w.orth_ == \"m_2\":\n",
    "                    window_2 = document[i-3:i+4]\n",
    "                    if window_2:\n",
    "                        for e in window_2:\n",
    "                            if e.orth_ == \"m_1\" or e.orth_ == \"m_2\":\n",
    "                                tagged_context_2.append(\"MENTION\")\n",
    "                            else:\n",
    "                                tagged_context_2.append(e.pos_)\n",
    "            \n",
    "            featurized_instance['tagged_context_1'] = ' '.join(tagged_context_1)\n",
    "            featurized_instance['tagged_context_2'] = ' '.join(tagged_context_2)\n",
    "            \n",
    "            edges = []\n",
    "            for w in document: # FYI https://spacy.io/docs/api/token\n",
    "                for child in w.children:\n",
    "                    edges.append(('{0}-{1}'.format(w.lower_, w.i),\n",
    "                                  '{0}-{1}'.format(child.lower_, child.i)))\n",
    "\n",
    "            graph = nx.Graph(edges)\n",
    "            for w in graph:\n",
    "                if \"m_1\" in w:\n",
    "                    s = w\n",
    "                if \"m_2\" in w:\n",
    "                    t = w\n",
    "            \n",
    "            try:\n",
    "                featurized_instance['path_length'] = nx.shortest_path_length(graph, source=s, target=t)\n",
    "            except nx.NetworkXNoPath: # unrelated?\n",
    "                featurized_instance['path_length'] = 0\n",
    "            except nx.NodeNotFound: # problem with mention\n",
    "                featurized_instance['path_length'] = 0.5\n",
    "\n",
    "        featurized_data.append(featurized_instance)\n",
    "        \n",
    "        if len(featurized_data)%5000 == 0:\n",
    "            print(\"{} instances processed for nlp.\".format(len(featurized_data)))\n",
    "                \n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "            \n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = UseNLP(train_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ExractSimpleFeatures(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EntityLengthFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each isntance for DictVectorizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return LengthOfEntities(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BowFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return SelectContext(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DependencyPath(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Considers pos tags of window around mentions and length of dependency path between mentions\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Applies spacy's nlp pipeline to data. Status indicates how many instances have been processed.\n",
    "        return UseNLP(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform labels to numeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "\n",
    "length_pipe = make_pipeline(EntityLengthFeaturizer(LengthOfEntities), DictVectorizer())\n",
    "\n",
    "bow_pipe = make_pipeline(BowFeaturizer(SelectContext), CountVectorizer(ngram_range=(1,3)))\n",
    "\n",
    "simple_pipe = make_pipeline(SimpleFeaturizer(ExractSimpleFeatures), DictVectorizer())\n",
    "\n",
    "# syntax_pipe = make_pipeline(DependencyPath(UseNLP), DictVectorizer())\n",
    "\n",
    "def build_classifier(syntactic_features=False):\n",
    "    if syntactic_features == True:\n",
    "        clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "            ('length_pipeline', length_pipe),\n",
    "            ('bow_pipeline', bow_pipe),\n",
    "            ('simple_pipeline', simple_pipe),\n",
    "            ('syntax_pipeline', syntax_pipe)]),\n",
    "            LogisticRegression())\n",
    "    \n",
    "    else:\n",
    "        # Without syntactic features\n",
    "        clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "            ('length_pipeline', length_pipe),\n",
    "            ('bow_pipeline', bow_pipe),\n",
    "            ('simple_pipeline', simple_pipe)]),\n",
    "            LogisticRegression())\n",
    "    \n",
    "    return clf\n",
    "\n",
    "clf = build_classifier(syntactic_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 3. TRAIN CLASSIFIER AND EVALUATE (CV)\n",
    "##################################################################################################\n",
    "\n",
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "    \n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    classifier: clf - pipeline with CountVevtorizer and Logistic regression\n",
    "    label_encoder: le - label encoder\n",
    "    X: train data featurized\n",
    "    y: train labels featurized\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "#         print(rel)\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            #print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "#             print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n"
     ]
    }
   ],
   "source": [
    "evaluateCV(clf, le, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A check for the average F1 score\n",
    "\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluateCV_check(clf, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 4. TEST PREDICTIONS and ANALYSIS\n",
    "##################################################################################################\n",
    "\n",
    "# Fit final model on the full train data\n",
    "clf.fit(train_data, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "test_data, test_labels = load_data('../data/test-covered.json.txt', verbose=False)\n",
    "print(len(test_data))\n",
    "print(len(test_labels))\n",
    "# test_data_featurized = SelectContext(test_data, verbose=False)\n",
    "test_label_predicted = clf.predict(test_data)\n",
    "print(len(test_label_predicted))\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(len(test_label_predicted_decoded))\n",
    "print(test_label_predicted_decoded[:2])\n",
    "f = open(\"outputs/test_labels2.txt\", 'w', encoding=\"utf-8\")\n",
    "for label in test_label_predicted_decoded:\n",
    "    f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Feature analysis - print N most informative\n",
    "# # !! Make changes in this function when you change the pipleine!!\n",
    "# def printNMostInformative(classifier,label_encoder,N):\n",
    "#     \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "#     feature_names = classifier.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "#     coef = classifier.named_steps['logisticregression'].coef_    \n",
    "#     print(coef.shape)\n",
    "#     for rel in label_encoder.classes_:\n",
    "#         rel_id = label_encoder.transform([rel])[0]\n",
    "#         coef_rel = coef[rel_id]\n",
    "#         coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "#         top_features = coefs_with_fns[-N:]\n",
    "#         print(\"\\nClass {} best: \".format(rel))\n",
    "#         for feat in top_features:\n",
    "#             print(feat)        \n",
    "        \n",
    "# print(\"Top features used to predict: \")\n",
    "# # show the top features\n",
    "# printNMostInformative(clf,le,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature analysis - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier,label_encoder,N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['length_pipeline'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf,le,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
