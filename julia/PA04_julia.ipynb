{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA4: Relation classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json example:\n",
      "{'entity_1': 'Judy_Garland', 'relation': 'has_spouse', 'entity_2': 'David_Rose', 'snippet': [{'right': '. Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair', 'direction': 'fwd', 'mention_1': 'Judy Garland', 'left': 'thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old', 'mention_2': 'David Rose', 'middle': 'while she was engaged to composer'}]}\n",
      "\n",
      "example transformed as a named tuple:\n",
      "PairExample(entity_1='Judy_Garland', entity_2='David_Rose', snippet=[Snippet(left='thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old', mention_1='Judy Garland', middle='while she was engaged to composer', mention_2='David Rose', right='. Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair', direction='fwd')])\n"
     ]
    }
   ],
   "source": [
    "PairExample = namedtuple('PairExample',\n",
    "                         'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "                     'left, mention_1, middle, mention_2, right, direction')\n",
    "\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i, line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "        if i == 0:\n",
    "            if verbose:\n",
    "                print('json example:')\n",
    "                print(instance)\n",
    "        # 'relation, entity_1, entity_2, snippet' fileds for each example\n",
    "        # 'left, mention_1, middle, mention_2, right, direction' for each snippet\n",
    "        instance_tuple = PairExample(instance['entity_1'], instance['entity_2'], [])\n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'], snippet['mention_1'],\n",
    "                                        snippet['middle'], \n",
    "                                        snippet['mention_2'], snippet['right'],\n",
    "                                        snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "            except:\n",
    "                print(instance)\n",
    "        if i == 0:\n",
    "            if verbose:\n",
    "                print('\\nexample transformed as a named tuple:')\n",
    "                print(instance_tuple)\n",
    "        data.append(instance_tuple)\n",
    "        labels.append(instance['relation'])\n",
    "\n",
    "    return data, labels\n",
    "    \n",
    "train_data, train_labels = load_data('data/train.json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics:\n",
      "                                rel_examples\n",
      "relation               examples /all_examples\n",
      "--------               --------    -------\n",
      "author                     2653       0.27\n",
      "worked_at                  1178       0.12\n",
      "has_spouse                 3019       0.31\n",
      "capital                     510       0.05\n",
      "NO_REL                     2300       0.24\n",
      "--------               --------    -------\n",
      "Total                      9660       1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dictionary: \n",
      "\n",
      "author Charlie_and_the_Chocolate_Factory Roald_Dahl\n",
      "worked_at Carl-Henric_Svanberg Ericsson\n",
      "has_spouse Judy_Garland David_Rose\n",
      "capital Andalusia Seville\n",
      "NO_REL Sichuan Tibet\n"
     ]
    }
   ],
   "source": [
    "# check that each entity pair is assigned only one relation\n",
    "pair_dict = {}\n",
    "rel_dict = {}\n",
    "\n",
    "for example, label in zip(train_data, train_labels):\n",
    "    if (example.entity_1, example.entity_2) not in pair_dict.keys():\n",
    "        pair_dict[(example.entity_1, example.entity_2)] = [label]\n",
    "    else:\n",
    "        pair_dict[(example.entity_1, example.entity_2)].append(label)\n",
    "        print(example.entity_1, example.entity_2, label)\n",
    "\n",
    "    if label not in rel_dict.keys():\n",
    "        rel_dict[label] = [example]\n",
    "    else:\n",
    "        rel_dict[label].append(example)\n",
    "\n",
    "print(\"Done building dictionary: \\n\")  \n",
    "    \n",
    "# example for each relation\n",
    "for rel in rel_dict.keys():\n",
    "    ex = rel_dict[rel][0]\n",
    "    print(rel, ex.entity_1, ex.entity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PairExample(entity_1='Judy_Garland', entity_2='David_Rose', snippet=[Snippet(left='thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old', mention_1='Judy Garland', middle='while she was engaged to composer', mention_2='David Rose', right='. Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair', direction='fwd')])\n",
      "\n",
      " full context:\n",
      "thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old Judy Garland while she was engaged to composer David Rose . Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair\n"
     ]
    }
   ],
   "source": [
    "# print full context\n",
    "ex = train_data[0]\n",
    "print(ex)\n",
    "print(\"\\n full context:\")\n",
    "ex_s = ex.snippet[0]\n",
    "ex_context = ' '.join((ex_s.left, ex_s.mention_1.replace(\" \", \"_\"), ex_s.middle, ex_s.mention_2.replace(\" \", \"_\"), ex_s.right))\n",
    "print(ex_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get full context\n",
    "def get_context(data, embed_mode=False):\n",
    "    all_data = []\n",
    "    for instance in data:\n",
    "        s_context = []\n",
    "        for s in instance.snippet:\n",
    "            if embed_mode:\n",
    "                s_context.append(' '.join((s.left, s.mention_1.replace(\" \", \"_\"), s.middle, s.mention_2.replace(\" \", \"_\"), s.right)))\n",
    "            else:\n",
    "                s_context.append(' '.join((s.left, s.mention_1, s.middle, s.mention_2, s.right)))\n",
    "            #s_context.append(' '.join((s.left, s.middle, s.right)))\n",
    "        all_data.append(' '.join(s_context))\n",
    "\n",
    "    print(len(all_data))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EXTRACT FEATURES and BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract two simple features\n",
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'mid_words':'',\n",
    "            'distance':np.inf,\n",
    "            'left':[],\n",
    "            'right':[],\n",
    "            'mid':[]\n",
    "        }\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "            featurized_instance['left'] = s.left\n",
    "            featurized_instance['right'] = s.right\n",
    "            featurized_instance['mid'] = s.middle\n",
    "            # context = [s.left + s.right + s.middle]\n",
    "            # vec_context = vectorizer.transform(context)\n",
    "            # featurized_instance['left'] = vectorizer.transform([s.left])\n",
    "            # featurized_instance['right'] = vectorizer.transform([s.right])\n",
    "            # featurized_instance['mid'] = vectorizer.transform([s.middle])\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(featurized_data))\n",
    "        print(data[0])\n",
    "        print(featurized_data[0])\n",
    "\n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_word2vec(data):\n",
    "    ''' Input: list of contexts (each context is a string).\n",
    "        Prepares data for training embeddings: tokenize with simple_preprocessing.\n",
    "        Returns: embedding model\n",
    "    '''\n",
    "    data_tokenised = [doc.lower().split(\" \") for doc in data]\n",
    "    # path_model = Path(\"models\") / \"Word2Vec.model\"\n",
    "\n",
    "    # if path_model.exists():\n",
    "    #     model = Word2Vec.load(str(path_model))\n",
    "    # else:\n",
    "    #     if not path_model.parent.exists():\n",
    "    #         path_model.parent.mkdir(parents=True)\n",
    "\n",
    "    model = Word2Vec(data_tokenised, size=100, min_count=1, sg=1)\n",
    "        # model.save(str(path_model))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_embeddings_feature(data, embed_model, verbose=True):\n",
    "    DIMEN_SIZE = 100\n",
    "    vectorized_data = np.zeros(shape=(len(data), DIMEN_SIZE))\n",
    "    for i, instance in enumerate(data):\n",
    "        instance_vectors = []\n",
    "        for s in instance.snippet:\n",
    "            word1 = s.mention_1.lower().replace(\" \", \"_\")\n",
    "            word2 = s.mention_2.lower().replace(\" \", \"_\")\n",
    "            word1_vector = embed_model.wv[word1]\n",
    "            word2_vector = embed_model.wv[word2]\n",
    "            instance_vectors.append(word1_vector)\n",
    "            instance_vectors.append(word2_vector)\n",
    "            \n",
    "        mean_vector = np.mean(np.array([vec for vec in instance_vectors]), axis=0)\n",
    "        vectorized_data[i] = mean_vector\n",
    "        \n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(vectorized_data))\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9660\n",
      "1840\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels = load_data('data/test.json.txt', verbose=False)\n",
    "\n",
    "all_train = get_context(train_data, embed_mode=True)\n",
    "all_test = get_context(test_data, embed_mode=True)\n",
    "\n",
    "# DATA ExractSimpleFeatures\n",
    "train_simple_featurized = ExractSimpleFeatures(train_data, verbose=False)\n",
    "test_simple_featurized = ExractSimpleFeatures(test_data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train embedding model\n",
    "emb_model = train_word2vec(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9660\n",
      "9660\n"
     ]
    }
   ],
   "source": [
    "# EMBEDDINGS\n",
    "train_embed_vectorized = extract_embeddings_feature(train_data, emb_model)\n",
    "# test_embed_vectorized = extract_embeddings_feature(test_data, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# MODEL\n",
    "\n",
    "# Transform labels to nimeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "\n",
    "# Fit model one vs rest logistic regression    \n",
    "#clf = make_pipeline(DictVectorizer(), LogisticRegression())\n",
    "\n",
    "# if with CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
    "TFiDF_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# clf = make_pipeline(bow_vectorizer, LogisticRegression())\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TRAIN CLASSIFIER AND EVALUATE (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "    \n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            #print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "            #print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.536      0.629      0.552       2300\n",
      "author                    0.832      0.822      0.830       2653\n",
      "capital                   0.705      0.498      0.650        510\n",
      "has_spouse                0.782      0.851      0.795       3019\n",
      "worked_at                 0.773      0.450      0.676       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.726      0.650      0.700       9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7004649820878264"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateCV(clf, le, train_embed_vectorized, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.669      0.721      0.679       2300\n",
      "author                    0.828      0.836      0.829       2653\n",
      "capital                   0.888      0.653      0.828        510\n",
      "has_spouse                0.874      0.902      0.879       3019\n",
      "worked_at                 0.755      0.643      0.730       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.803      0.751      0.789       9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7890200518748698"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE\n",
    "evaluateCV(clf, le, train_embed_vectorized, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A check for the average F1 score\n",
    "\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.77831464 0.77490296 0.78322361 0.77969274 0.78449379]\n",
      "Mean cv score (StratifiedKFold):  0.7801255472002809\n"
     ]
    }
   ],
   "source": [
    "evaluateCV_check(clf, train_embed_vectorized, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TEST PREDICTIONS and ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capital' 'capital' 'worked_at' 'NO_REL' 'has_spouse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigma/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Fit final model on the full train data\n",
    "clf.fit(train_embed_vectorized, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "test_label_predicted = clf.predict(test_embed_vectorized)\n",
    "\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(test_label_predicted_decoded[:5])\n",
    "f = open(\"test_labels.txt\", 'w', encoding=\"utf-8\")\n",
    "for label in test_label_predicted_decoded:\n",
    "    f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features used to predict: \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-1bcdbd1eda6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top features used to predict: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# show the top features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprintNMostInformative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-1bcdbd1eda6d>\u001b[0m in \u001b[0;36mprintNMostInformative\u001b[0;34m(classifier, label_encoder, N)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintNMostInformative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Prints features with the highest coefficient values, per class\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dictvectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logisticregression'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "# Feature analisys - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier, label_encoder, N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['dictvectorizer'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf, le, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
