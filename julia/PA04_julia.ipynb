{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA4: Relation classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json example:\n",
      "{'entity_1': 'Judy_Garland', 'relation': 'has_spouse', 'entity_2': 'David_Rose', 'snippet': [{'right': '. Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair', 'direction': 'fwd', 'mention_1': 'Judy Garland', 'left': 'thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old', 'mention_2': 'David Rose', 'middle': 'while she was engaged to composer'}]}\n",
      "\n",
      "example transformed as a named tuple:\n",
      "PairExample(entity_1='Judy_Garland', entity_2='David_Rose', snippet=[Snippet(left='thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old', mention_1='Judy Garland', middle='while she was engaged to composer', mention_2='David Rose', right='. Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair', direction='fwd')])\n"
     ]
    }
   ],
   "source": [
    "PairExample = namedtuple('PairExample',\n",
    "                         'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "                     'left, mention_1, middle, mention_2, right, direction')\n",
    "\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i, line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "        if i == 0:\n",
    "            if verbose:\n",
    "                print('json example:')\n",
    "                print(instance)\n",
    "        # 'relation, entity_1, entity_2, snippet' fileds for each example\n",
    "        # 'left, mention_1, middle, mention_2, right, direction' for each snippet\n",
    "        instance_tuple = PairExample(instance['entity_1'], instance['entity_2'], [])\n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'], snippet['mention_1'],\n",
    "                                        snippet['middle'], \n",
    "                                        snippet['mention_2'], snippet['right'],\n",
    "                                        snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "            except:\n",
    "                print(instance)\n",
    "        if i == 0:\n",
    "            if verbose:\n",
    "                print('\\nexample transformed as a named tuple:')\n",
    "                print(instance_tuple)\n",
    "        data.append(instance_tuple)\n",
    "        labels.append(instance['relation'])\n",
    "\n",
    "    return data, labels\n",
    "    \n",
    "X_data, y_labels = load_data('data/train.json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, dev_data, train_labels, dev_labels = train_test_split(X_data, y_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics:\n",
      "                                rel_examples\n",
      "relation               examples /all_examples\n",
      "--------               --------    -------\n",
      "author                     2124       0.27\n",
      "NO_REL                     1827       0.24\n",
      "has_spouse                 2426       0.31\n",
      "capital                     399       0.05\n",
      "worked_at                   952       0.12\n",
      "--------               --------    -------\n",
      "Total                      7728       1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dictionary: \n",
      "\n",
      "author Daisy_Miller Henry_James\n",
      "NO_REL CNN Television\n",
      "has_spouse Beatrix_of_the_Netherlands Prince_Claus_of_the_Netherlands\n",
      "capital Socialist_Federal_Republic_of_Yugoslavia Belgrade\n",
      "worked_at John_Hagelin Maharishi_University_of_Management\n"
     ]
    }
   ],
   "source": [
    "# check that each entity pair is assigned only one relation\n",
    "pair_dict = {}\n",
    "rel_dict = {}\n",
    "\n",
    "for example, label in zip(train_data, train_labels):\n",
    "    if (example.entity_1, example.entity_2) not in pair_dict.keys():\n",
    "        pair_dict[(example.entity_1, example.entity_2)] = [label]\n",
    "    else:\n",
    "        pair_dict[(example.entity_1, example.entity_2)].append(label)\n",
    "        print(example.entity_1, example.entity_2, label)\n",
    "\n",
    "    if label not in rel_dict.keys():\n",
    "        rel_dict[label] = [example]\n",
    "    else:\n",
    "        rel_dict[label].append(example)\n",
    "\n",
    "print(\"Done building dictionary: \\n\")  \n",
    "    \n",
    "# example for each relation\n",
    "for rel in rel_dict.keys():\n",
    "    ex = rel_dict[rel][0]\n",
    "    print(rel, ex.entity_1, ex.entity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PairExample(entity_1='Daisy_Miller', entity_2='Henry_James', snippet=[Snippet(left='imprisoned there from 1530 to 1536 ; Byron also carved his name on a pillar of the dungeon . The castle is one of the settings in', mention_1='Henry James', middle='‘ s novella', mention_2='Daisy Miller', right='( 1878 ) . The history of Chillon was influenced by 3 major periods : the Savoy Period , the Bernese Period and the Vaudois Period . [ 2 ] “ Here are a', direction='bwd'), Snippet(left='imprisoned there from 1530 to 1536 ; Byron also carved his name on a pillar of the dungeon . The castle is one of the settings in', mention_1='Henry James', middle=\"'s novella\", mention_2='Daisy Miller', right=\"( 1878 ) . Chillon is currently open to the public for visits and tours . Chillon is listed as `` Switzerlands most visited historic monument '' . There is a\", direction='bwd'), Snippet(left='. It was thought that Roman fever was contracted at night , and thus that it was dangerous to venture out , a belief that American authors', mention_1='Henry James', middle='and Edith Wharton employ in their stories ``', mention_2='Daisy Miller', right=\"`` and `` Roman Fever , '' respectively . Class 4 : Discuss Mrs. Ansley and Mrs. Slade ’ s “ friendship ” . How have they made their bond ?\", direction='bwd'), Snippet(left='encouraged independence and travel . Affairs and intrigues , particularly between American heiresses and down-on their luck European aristocrats , continued steadily until World War I and inspired', mention_1='Henry James', middle=\"'s\", mention_2='Daisy Miller', right=\", Joaquin Miller 's The One Fair Woman , and much of the early output of E.M. Forster . Female sex travel declined from the time\", direction='bwd'), Snippet(left='still broadcasts each day from its Balltown Road studios in Niskyuna , just outside the city line , but still in Schenectady County . The title character of', mention_1='Henry James', middle=\"' novella\", mention_2='Daisy Miller', right=\"is from Schenectady . The official song of Schenectady , entitled `` Our Schenectady , '' was composed by John Van Laak and was sung by Judi Merriam . It was\", direction='bwd'), Snippet(left='heavy-handed , but to allowissues to emerge from the text instead , applies to non-fiction writing too . The principle An early example of giving this advice lieswith', mention_1='Henry James', middle='.In the preface to the New York edition of', mention_2='Daisy Miller', right=\", he left a pencil-mark in the margins of his notes , reminding himself to '' Dramatize , dramatize ! '' The mantra `` Show , do n't tell '' has becomestock advice for fiction-writers . Janet\", direction='bwd'), Snippet(left='Criticism ” ) : “ Low mimetic tragedy shows the death or sacrifice of an ordinary human being and evokes pathos , as with Thomas Hardy ‘ s Tess or', mention_1='Henry James', middle='‘ s', mention_2='Daisy Miller', right='… . Low mimetic comedy often shows the social elevation of the hero or heroine and often ends in marriage. ” Melodrama Originally , a dramatic genre in', direction='bwd'), Snippet(left='better than her tuition . But the salient point of course is simply that the Sirens are seductive , and dangerously so , too . Anyone who ever read', mention_1='Henry James', middle='‘ s 1878 novella', mention_2='Daisy Miller', right='knows what “ Italy , ” and more particularly “ Rome ” signified to the proper Northern European/New England type in mid-19th century America : a place as seductive as it', direction='bwd')])\n",
      "\n",
      " full context:\n",
      "imprisoned there from 1530 to 1536 ; Byron also carved his name on a pillar of the dungeon . The castle is one of the settings in Henry_James ‘ s novella Daisy_Miller ( 1878 ) . The history of Chillon was influenced by 3 major periods : the Savoy Period , the Bernese Period and the Vaudois Period . [ 2 ] “ Here are a\n"
     ]
    }
   ],
   "source": [
    "# print full context\n",
    "ex = train_data[0]\n",
    "print(ex)\n",
    "print(\"\\n full context:\")\n",
    "ex_s = ex.snippet[0]\n",
    "ex_context = ' '.join((ex_s.left, ex_s.mention_1.replace(\" \", \"_\"), ex_s.middle, ex_s.mention_2.replace(\" \", \"_\"), ex_s.right))\n",
    "# print(ex_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get full context\n",
    "def get_context(data, embed_mode=False):\n",
    "    all_data = []\n",
    "    for instance in data:\n",
    "        s_context = []\n",
    "        for s in instance.snippet:\n",
    "            if embed_mode:\n",
    "                s_context.append(' '.join((s.left, s.mention_1.replace(\" \", \"_\"), s.middle, s.mention_2.replace(\" \", \"_\"), s.right)))\n",
    "            else:\n",
    "                s_context.append(' '.join((s.left, s.mention_1, s.middle, s.mention_2, s.right)))\n",
    "                # s_context.append(' '.join((s.left, s.middle, s.right)))\n",
    "        all_data.append(' '.join(s_context))\n",
    "\n",
    "    print(len(all_data))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EXTRACT FEATURES and BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract two simple features\n",
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'mid_words':'',\n",
    "            'distance':np.inf,\n",
    "            'left':[],\n",
    "            'right':[],\n",
    "            'mid':[]\n",
    "        }\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "            featurized_instance['left'] = s.left\n",
    "            featurized_instance['right'] = s.right\n",
    "            featurized_instance['mid'] = s.middle\n",
    "            # context = [s.left + s.right + s.middle]\n",
    "            # vec_context = vectorizer.transform(context)\n",
    "            # featurized_instance['left'] = vectorizer.transform([s.left])\n",
    "            # featurized_instance['right'] = vectorizer.transform([s.right])\n",
    "            # featurized_instance['mid'] = vectorizer.transform([s.middle])\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(featurized_data))\n",
    "        print(data[0])\n",
    "        print(featurized_data[0])\n",
    "\n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_word2vec(data, pretrained=True):\n",
    "    ''' Input: list of contexts (each context is a string).\n",
    "        Prepares data for training embeddings: tokenize with simple_preprocessing.\n",
    "        Returns: embedding model\n",
    "    '''\n",
    "    data_tokenised = [doc.lower().split(\" \") for doc in data]\n",
    "    # path_model = Path(\"models\") / \"Word2Vec.model\"\n",
    "\n",
    "    # if path_model.exists():\n",
    "    #     model = Word2Vec.load(str(path_model))\n",
    "    # else:\n",
    "    #     if not path_model.parent.exists():\n",
    "    #         path_model.parent.mkdir(parents=True)\n",
    "    if pretrained:\n",
    "        model = Word2Vec.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "    else:\n",
    "        model = Word2Vec(data_tokenised, size=100, min_count=1, sg=1)\n",
    "        # model.save(str(path_model))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_embeddings_feature(data, embed_model, verbose=True):\n",
    "    DIMEN_SIZE = 100\n",
    "    vectorized_data = np.zeros(shape=(len(data), DIMEN_SIZE))\n",
    "    for i, instance in enumerate(data):\n",
    "        instance_vectors = []\n",
    "        for s in instance.snippet:\n",
    "            word1 = s.mention_1.lower().replace(\" \", \"_\")\n",
    "            word2 = s.mention_2.lower().replace(\" \", \"_\")\n",
    "            word1_vector = embed_model.wv[word1]\n",
    "            word2_vector = embed_model.wv[word2]\n",
    "            instance_vectors.append(word1_vector)\n",
    "            instance_vectors.append(word2_vector)\n",
    "            \n",
    "        mean_vector = np.mean(np.array([vec for vec in instance_vectors]), axis=0)\n",
    "        vectorized_data[i] = mean_vector\n",
    "        \n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(vectorized_data))\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'has_spouse', 'has_spouse', 'NO_REL', 'author', 'has_spouse', 'author', 'author', 'worked_at', 'author']\n",
      "7728\n",
      "1932\n",
      "1840\n",
      "[\"imprisoned there from 1530 to 1536 ; Byron also carved his name on a pillar of the dungeon . The castle is one of the settings in Henry James ‘ s novella Daisy Miller ( 1878 ) . The history of Chillon was influenced by 3 major periods : the Savoy Period , the Bernese Period and the Vaudois Period . [ 2 ] “ Here are a imprisoned there from 1530 to 1536 ; Byron also carved his name on a pillar of the dungeon . The castle is one of the settings in Henry James 's novella Daisy Miller ( 1878 ) . Chillon is currently open to the public for visits and tours . Chillon is listed as `` Switzerlands most visited historic monument '' . There is a . It was thought that Roman fever was contracted at night , and thus that it was dangerous to venture out , a belief that American authors Henry James and Edith Wharton employ in their stories `` Daisy Miller `` and `` Roman Fever , '' respectively . Class 4 : Discuss Mrs. Ansley and Mrs. Slade ’ s “ friendship ” . How have they made their bond ? encouraged independence and travel . Affairs and intrigues , particularly between American heiresses and down-on their luck European aristocrats , continued steadily until World War I and inspired Henry James 's Daisy Miller , Joaquin Miller 's The One Fair Woman , and much of the early output of E.M. Forster . Female sex travel declined from the time still broadcasts each day from its Balltown Road studios in Niskyuna , just outside the city line , but still in Schenectady County . The title character of Henry James ' novella Daisy Miller is from Schenectady . The official song of Schenectady , entitled `` Our Schenectady , '' was composed by John Van Laak and was sung by Judi Merriam . It was heavy-handed , but to allowissues to emerge from the text instead , applies to non-fiction writing too . The principle An early example of giving this advice lieswith Henry James .In the preface to the New York edition of Daisy Miller , he left a pencil-mark in the margins of his notes , reminding himself to '' Dramatize , dramatize ! '' The mantra `` Show , do n't tell '' has becomestock advice for fiction-writers . Janet Criticism ” ) : “ Low mimetic tragedy shows the death or sacrifice of an ordinary human being and evokes pathos , as with Thomas Hardy ‘ s Tess or Henry James ‘ s Daisy Miller … . Low mimetic comedy often shows the social elevation of the hero or heroine and often ends in marriage. ” Melodrama Originally , a dramatic genre in better than her tuition . But the salient point of course is simply that the Sirens are seductive , and dangerously so , too . Anyone who ever read Henry James ‘ s 1878 novella Daisy Miller knows what “ Italy , ” and more particularly “ Rome ” signified to the proper Northern European/New England type in mid-19th century America : a place as seductive as it\"]\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels = load_data('data/test.json.txt', verbose=False)\n",
    "print(dev_labels[:10])\n",
    "\n",
    "all_train = get_context(train_data, embed_mode=False)\n",
    "all_dev = get_context(dev_data, embed_mode=False)\n",
    "all_test = get_context(test_data, embed_mode=False)\n",
    "\n",
    "print(all_train[:1])\n",
    "# DATA ExractSimpleFeatures\n",
    "#train_simple_featurized = ExractSimpleFeatures(train_data, verbose=False)\n",
    "#dev_simple_featurized = ExractSimpleFeatures(dev_data, verbose=False)\n",
    "#test_simple_featurized = ExractSimpleFeatures(test_data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train embedding model\n",
    "emb_model = train_word2vec(all_train, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9660\n",
      "9660\n"
     ]
    }
   ],
   "source": [
    "# EMBEDDINGS\n",
    "train_embed_vectorized = extract_embeddings_feature(train_data, emb_model)\n",
    "dev_embed_vectorized = extract_embeddings_feature(dev_data, emb_model)\n",
    "# test_embed_vectorized = extract_embeddings_feature(test_data, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO_REL' 'author' 'capital' 'has_spouse' 'worked_at']\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# MODEL\n",
    "\n",
    "# Transform labels to nimeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "dev_labels_featurized = le.transform(dev_labels)\n",
    "\n",
    "print(le.classes_)\n",
    "\n",
    "# Fit model one vs rest logistic regression    \n",
    "#clf = make_pipeline(DictVectorizer(), LogisticRegression())\n",
    "\n",
    "# if with CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "TFiDF_vectorizer = TfidfVectorizer()\n",
    "\n",
    "clf = make_pipeline(bow_vectorizer, LogisticRegression())\n",
    "# clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TRAIN CLASSIFIER AND EVALUATE (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "    \n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            # print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "                # print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.650      0.737      0.666       1827\n",
      "author                    0.830      0.829      0.830       2124\n",
      "capital                   0.922      0.654      0.850        399\n",
      "has_spouse                0.863      0.878      0.866       2426\n",
      "worked_at                 0.763      0.627      0.731        952\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.806      0.745      0.789       7728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7885812878907923"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateCV(clf, le, all_train, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.669      0.721      0.679       2300\n",
      "author                    0.828      0.836      0.829       2653\n",
      "capital                   0.888      0.653      0.828        510\n",
      "has_spouse                0.874      0.902      0.879       3019\n",
      "worked_at                 0.755      0.643      0.730       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.803      0.751      0.789       9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7890200518748698"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE\n",
    "evaluateCV(clf, le, all_train, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A check for the average F1 score\n",
    "\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.77831464 0.77490296 0.78322361 0.77969274 0.78449379]\n",
      "Mean cv score (StratifiedKFold):  0.7801255472002809\n"
     ]
    }
   ],
   "source": [
    "evaluateCV_check(clf, all_train, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TEST PREDICTIONS and ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit final model on the full train data\n",
    "clf.fit(all_train, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "dev_label_predicted = clf.predict(all_dev)\n",
    "test_label_predicted = clf.predict(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['NO_REL', 'author', 'has_spouse', 'capital', 'worked_at']\n",
      "[1 3 3 0 1 3 1 1 4 1 4 0 1 1 0 0 1 2 2 2 3 4 1 0 0 3 3 3 3 0]\n",
      "[1 3 3 0 1 3 1 1 1 1 0 0 1 1 0 4 1 2 2 0 3 4 1 0 0 3 3 3 3 0]\n",
      "0.7859857572352148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     NO_REL       0.66      0.73      0.70       473\n",
      "     author       0.84      0.82      0.83       529\n",
      " has_spouse       0.86      0.57      0.68       111\n",
      "    capital       0.86      0.89      0.87       593\n",
      "  worked_at       0.73      0.65      0.69       226\n",
      "\n",
      "avg / total       0.79      0.79      0.79      1932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = dev_labels_featurized\n",
    "labels = list(set(train_labels))\n",
    "\n",
    "final_score = f1_score(y_true, dev_label_predicted, average='weighted')\n",
    "print(\"Labels: \", labels)\n",
    "print(y_true[:30])\n",
    "print(dev_label_predicted[:30])\n",
    "\n",
    "print(final_score)\n",
    "print(classification_report(y_true, dev_label_predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['NO_REL', 'author', 'has_spouse', 'capital', 'worked_at']\n",
      "[1 3 3 0 1 3 1 1 4 1 4 0 1 1 0 0 1 2 2 2 3 4 1 0 0 3 3 3 3 0]\n",
      "[1 3 3 0 1 3 1 1 0 1 4 0 1 1 0 4 1 2 2 0 3 4 1 0 0 3 3 3 3 0]\n",
      "0.7964352138567375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     NO_REL       0.65      0.79      0.72       473\n",
      "     author       0.84      0.84      0.84       529\n",
      " has_spouse       0.94      0.53      0.68       111\n",
      "    capital       0.88      0.88      0.88       593\n",
      "  worked_at       0.81      0.62      0.70       226\n",
      "\n",
      "avg / total       0.81      0.80      0.80      1932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = dev_labels_featurized\n",
    "labels = list(set(train_labels))\n",
    "\n",
    "final_score = f1_score(y_true, dev_label_predicted, average='weighted')\n",
    "print(\"Labels: \", labels)\n",
    "print(y_true[:30])\n",
    "print(dev_label_predicted[:30])\n",
    "\n",
    "print(final_score)\n",
    "print(classification_report(y_true, dev_label_predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capital' 'NO_REL' 'worked_at' 'NO_REL' 'has_spouse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigma/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# ON TEST DATA: TO UPLOAD\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(test_label_predicted_decoded[:5])\n",
    "f = open(\"test_labels.txt\", 'w', encoding=\"utf-8\")\n",
    "for label in test_label_predicted_decoded:\n",
    "    f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features used to predict: \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-1bcdbd1eda6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top features used to predict: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# show the top features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprintNMostInformative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-1bcdbd1eda6d>\u001b[0m in \u001b[0;36mprintNMostInformative\u001b[0;34m(classifier, label_encoder, N)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintNMostInformative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Prints features with the highest coefficient values, per class\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dictvectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logisticregression'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "# Feature analisys - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier, label_encoder, N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['dictvectorizer'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf, le, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
