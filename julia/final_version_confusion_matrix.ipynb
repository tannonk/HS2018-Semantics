{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this script sets a baseline for relation extraction using frequency-based BOW model\n",
    "\n",
    "#### add additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# import networkx as nx\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 1. LOAD DATA ALTERED\n",
    "##################################################################################################\n",
    "\n",
    "PairExample = namedtuple('PairExample',\n",
    "    'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "    'left, mention_1, middle, mention_2, right, direction')\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i,line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "\n",
    "        instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "        \n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'],snippet['mention_1'],snippet['middle'],\n",
    "                                   snippet['mention_2'],snippet['right'],\n",
    "                                    snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "                \n",
    "                data.append(instance_tuple)\n",
    "                labels.append(instance['relation'])\n",
    "                instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "                \n",
    "            except:\n",
    "                print(instance)\n",
    "\n",
    "\n",
    "    return data,labels\n",
    "    \n",
    "train_data, train_labels = load_data('data/train.json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics:\n",
      "                                rel_examples\n",
      "relation               examples /all_examples\n",
      "--------               --------    -------\n",
      "author                    13113       0.31\n",
      "worked_at                  3669       0.09\n",
      "NO_REL                     3068       0.07\n",
      "has_spouse                13061       0.31\n",
      "capital                    9427       0.22\n",
      "--------               --------    -------\n",
      "Total                     42338       1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check that each entity pair is assigned only one relation\n",
    "# pair_dict={}\n",
    "# rel_dict={}\n",
    "# for example, label in zip(train_data,train_labels):\n",
    "#     if (example.entity_1,example.entity_2) not in pair_dict.keys():\n",
    "#         pair_dict[(example.entity_1,example.entity_2)] = [label]\n",
    "        \n",
    "#     else:\n",
    "#         pair_dict[(example.entity_1,example.entity_2)].append(label)\n",
    "# #         print(example.entity_1,example.entity_2,label)\n",
    "#     if label not in rel_dict.keys():\n",
    "#         rel_dict[label] = [example]\n",
    "#     else:\n",
    "#         rel_dict[label].append(example)\n",
    "# print(\"Done building dictionary\")  \n",
    "    \n",
    "# # example for each relation\n",
    "# for rel in rel_dict.keys():\n",
    "#     ex = rel_dict[rel][0]\n",
    "#     print(rel,ex.entity_1,ex.entity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SelectContext(data, verbose=True):\n",
    "    \"\"\"BOW feature extraction\"\"\"\n",
    "    only_context_data = []\n",
    "    for instance in data:\n",
    "        \n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            instance_context.append(context)\n",
    "        only_context_data.append(' '.join(instance_context))\n",
    "    if verbose:\n",
    "        print(len(only_context_data))\n",
    "        print(only_context_data[0])\n",
    "        print(only_context_data[0])\n",
    "    return only_context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = SelectContext(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    \"\"\"Considers length and words of middle segment\"\"\"\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {'mid_words': '', 'distance': np.inf}\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = ExractSimpleFeatures(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LengthOfEntities(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'entity1_len': len(instance.entity_1.split(\"_\")),\n",
    "            'entity2_len': len(instance.entity_2.split(\"_\")),\n",
    "            'combined_len': len(instance.entity_1.split(\"_\")) + len(instance.entity_2.split(\"_\"))\n",
    "        }\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = LengthOfEntities(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UseNLP(data, verbose=True):\n",
    "    \"\"\"\n",
    "    Processes each data instance with Spacy's nlp pipeline \n",
    "    and collects POS tags for context window around mentions\n",
    "    as well as length of dependency path between two mentions\n",
    "    \"\"\"\n",
    "    featurized_data = []\n",
    "\n",
    "    for instance in data:\n",
    "        featurized_instance = {'tagged_context_1': '', 'tagged_context_2': '', 'path_length': 0}\n",
    "\n",
    "        for s in instance.snippet:\n",
    "            \n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            \n",
    "            document = nlp(context) # spacy pipeline\n",
    "            \n",
    "            tagged_context_1 = []\n",
    "            tagged_context_2 = []\n",
    "            \n",
    "            for i, w in enumerate(document):\n",
    "                if w.orth_ == \"m_1\":\n",
    "                    window_1 = document[i-3:i+4]\n",
    "                    for e in window_1:\n",
    "                        if e.orth_ == \"m_1\" or e.orth_ == \"m_2\":\n",
    "                            tagged_context_1.append(\"MENTION\")\n",
    "                        else:\n",
    "                            tagged_context_1.append(e.pos_)\n",
    "                \n",
    "                if w.orth_ == \"m_2\":\n",
    "                    window_2 = document[i-3:i+4]\n",
    "                    if window_2:\n",
    "                        for e in window_2:\n",
    "                            if e.orth_ == \"m_1\" or e.orth_ == \"m_2\":\n",
    "                                tagged_context_2.append(\"MENTION\")\n",
    "                            else:\n",
    "                                tagged_context_2.append(e.pos_)\n",
    "            \n",
    "            featurized_instance['tagged_context_1'] = ' '.join(tagged_context_1)\n",
    "            featurized_instance['tagged_context_2'] = ' '.join(tagged_context_2)\n",
    "            \n",
    "            edges = []\n",
    "            for w in document: # FYI https://spacy.io/docs/api/token\n",
    "                for child in w.children:\n",
    "                    edges.append(('{0}-{1}'.format(w.lower_, w.i),\n",
    "                                  '{0}-{1}'.format(child.lower_, child.i)))\n",
    "\n",
    "            graph = nx.Graph(edges)\n",
    "            for w in graph:\n",
    "                if \"m_1\" in w:\n",
    "                    s = w\n",
    "                if \"m_2\" in w:\n",
    "                    t = w\n",
    "            \n",
    "            try:\n",
    "                featurized_instance['path_length'] = nx.shortest_path_length(graph, source=s, target=t)\n",
    "            except nx.NetworkXNoPath: # unrelated?\n",
    "                featurized_instance['path_length'] = 0\n",
    "            except nx.NodeNotFound: # problem with mention\n",
    "                featurized_instance['path_length'] = 0.5\n",
    "\n",
    "        featurized_data.append(featurized_instance)\n",
    "        \n",
    "        if len(featurized_data)%5000 == 0:\n",
    "            print(\"{} instances processed for nlp.\".format(len(featurized_data)))\n",
    "                \n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "            \n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_feat = UseNLP(train_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ExractSimpleFeatures(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EntityLengthFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each isntance for DictVectorizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return LengthOfEntities(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BowFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return SelectContext(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DependencyPath(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Considers pos tags of window around mentions and length of dependency path between mentions\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Applies spacy's nlp pipeline to data. Status indicates how many instances have been processed.\n",
    "        return UseNLP(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform labels to numeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "\n",
    "length_pipe = make_pipeline(EntityLengthFeaturizer(LengthOfEntities), DictVectorizer())\n",
    "\n",
    "bow_pipe = make_pipeline(BowFeaturizer(SelectContext), CountVectorizer(ngram_range=(1,3)))\n",
    "\n",
    "simple_pipe = make_pipeline(SimpleFeaturizer(ExractSimpleFeatures), DictVectorizer())\n",
    "\n",
    "# syntax_pipe = make_pipeline(DependencyPath(UseNLP), DictVectorizer())\n",
    "\n",
    "def build_classifier(syntactic_features=False):\n",
    "    if syntactic_features == True:\n",
    "        clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "            ('length_pipeline', length_pipe),\n",
    "            ('bow_pipeline', bow_pipe),\n",
    "            ('simple_pipeline', simple_pipe),\n",
    "            ('syntax_pipeline', syntax_pipe)]),\n",
    "            LogisticRegression())\n",
    "    \n",
    "    else:\n",
    "        # Without syntactic features\n",
    "        clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "            ('length_pipeline', length_pipe),\n",
    "            ('bow_pipeline', bow_pipe),\n",
    "            ('simple_pipeline', simple_pipe)]),\n",
    "            LogisticRegression())\n",
    "    \n",
    "    return clf\n",
    "\n",
    "clf = build_classifier(syntactic_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 3. TRAIN CLASSIFIER AND EVALUATE (CV)\n",
    "##################################################################################################\n",
    "\n",
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "    \n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    classifier: clf - pipeline with CountVevtorizer and Logistic regression\n",
    "    label_encoder: le - label encoder\n",
    "    X: train data featurized\n",
    "    y: train labels featurized\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "#         print(rel)\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            #print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "#             print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.778      0.401      0.654       3068\n",
      "author                    0.932      0.971      0.939      13113\n",
      "capital                   0.940      0.973      0.946       9427\n",
      "has_spouse                0.910      0.977      0.923      13061\n",
      "worked_at                 0.905      0.816      0.886       3669\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.893      0.828      0.870      42338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8696233397953861"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateCV(clf, le, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A check for the average F1 score\n",
    "\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluateCV_check(clf, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 4. TEST PREDICTIONS and ANALYSIS\n",
    "##################################################################################################\n",
    "\n",
    "# Fit final model on the full train data\n",
    "clf.fit(train_data, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "test_data, test_labels = load_data('../data/test-covered.json.txt', verbose=False)\n",
    "print(len(test_data))\n",
    "print(len(test_labels))\n",
    "# test_data_featurized = SelectContext(test_data, verbose=False)\n",
    "test_label_predicted = clf.predict(test_data)\n",
    "print(len(test_label_predicted))\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(len(test_label_predicted_decoded))\n",
    "print(test_label_predicted_decoded[:2])\n",
    "f = open(\"outputs/test_labels2.txt\", 'w', encoding=\"utf-8\")\n",
    "for label in test_label_predicted_decoded:\n",
    "    f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Feature analysis - print N most informative\n",
    "# # !! Make changes in this function when you change the pipleine!!\n",
    "# def printNMostInformative(classifier,label_encoder,N):\n",
    "#     \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "#     feature_names = classifier.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "#     coef = classifier.named_steps['logisticregression'].coef_    \n",
    "#     print(coef.shape)\n",
    "#     for rel in label_encoder.classes_:\n",
    "#         rel_id = label_encoder.transform([rel])[0]\n",
    "#         coef_rel = coef[rel_id]\n",
    "#         coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "#         top_features = coefs_with_fns[-N:]\n",
    "#         print(\"\\nClass {} best: \".format(rel))\n",
    "#         for feat in top_features:\n",
    "#             print(feat)        \n",
    "        \n",
    "# print(\"Top features used to predict: \")\n",
    "# # show the top features\n",
    "# printNMostInformative(clf,le,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature analysis - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier,label_encoder,N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['length_pipeline'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf,le,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "PairExample = namedtuple('PairExample',\n",
    "                         'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "                     'left, mention_1, middle, mention_2, right, direction')\n",
    "\n",
    "def load_test_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i, line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "        if i == 0:\n",
    "            if verbose:\n",
    "                print('json example:')\n",
    "                print(instance)\n",
    "        # 'relation, entity_1, entity_2, snippet' fileds for each example\n",
    "        # 'left, mention_1, middle, mention_2, right, direction' for each snippet\n",
    "        instance_tuple = PairExample(instance['entity_1'], instance['entity_2'], [])\n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'], snippet['mention_1'],\n",
    "                                        snippet['middle'], \n",
    "                                        snippet['mention_2'], snippet['right'],\n",
    "                                        snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "            except:\n",
    "                print(instance)\n",
    "        if i == 0:\n",
    "            if verbose:\n",
    "                print('\\nexample transformed as a named tuple:')\n",
    "                print(instance_tuple)\n",
    "        data.append(instance_tuple)\n",
    "        labels.append(instance['relation'])\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "test_data, test_labels = load_test_data('data/test.json.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('length_pipeline', Pipeline(memory=None,\n",
       "     steps=[('entitylengthfeaturizer', EntityLengthFeaturizer(featurizer=None)), ('dictvectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit final model on the full train data\n",
    "clf.fit(train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_labels_featurized = le.transform(test_labels)\n",
    "test_label_predicted = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    capital       0.00      0.00      0.00         0\n",
      "     author       0.95      0.93      0.94       663\n",
      "  worked_at       0.67      0.98      0.79       127\n",
      "     NO_REL       0.97      0.97      0.97       755\n",
      " has_spouse       0.96      0.74      0.84       295\n",
      "\n",
      "avg / total       0.94      0.92      0.93      1840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigma/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_true = test_labels_featurized\n",
    "labels = list(set(train_labels))\n",
    "\n",
    "print(classification_report(y_true, test_label_predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['capital', 'author', 'worked_at', 'NO_REL', 'has_spouse']\n",
      "[2 4 4 4 3 1 1 3 1 3 3 1 4 3 3 1 3 4 1 1 1 1 1 2 3 3 3 1 4 3]\n",
      "[2 0 4 4 3 1 1 3 1 4 3 1 4 3 3 1 3 4 1 1 1 4 1 2 3 3 3 1 2 3]\n",
      "0.9251234656627951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigma/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [  4, 616,  29,  13,   1],\n",
       "       [  1,   1, 124,   0,   1],\n",
       "       [  8,   4,   5, 732,   6],\n",
       "       [  9,  26,  28,  13, 219]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score = f1_score(y_true, test_label_predicted, average='weighted')\n",
    "print(\"Labels: \", labels)\n",
    "print(y_true[:30])\n",
    "print(test_label_predicted[:30])\n",
    "\n",
    "print(final_score)\n",
    "confusion_matrix(y_true, test_label_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capital', 'author', 'worked_at', 'NO_REL', 'has_spouse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigma/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/inigma/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[124,   1,   1,   1,   0],\n",
       "       [ 29, 616,   1,   4,  13],\n",
       "       [ 28,  26, 219,   9,  13],\n",
       "       [  0,   0,   0,   0,   0],\n",
       "       [  5,   4,   6,   8, 732]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_decoded = le.inverse_transform(y_true)\n",
    "y_pred_decoded = le.inverse_transform(test_label_predicted)\n",
    "\n",
    "print(labels)\n",
    "cm = confusion_matrix(y_true_decoded, y_pred_decoded, labels=labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEQCAYAAACUf04DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8f8BqgNn+HhmeOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130db3da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
