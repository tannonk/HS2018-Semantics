{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Anastassia Shaitarova, Julia Nigmatulina, Tannon Kew\n",
    "# the script takes about 14 min to run\n",
    "# the stdout results can also be seen in printed.log.txt\n",
    "##\n",
    "# To Run:\n",
    "# pass train data, test data, and outfile for labels to the script\n",
    "# python3 PA4_classifier.py train.json.txt test-covered.json.txt test_labels.txt\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     train_file = sys.argv[1]\n",
    "#     test_file = sys.argv[2]\n",
    "#     outfile = sys.argv[3]\n",
    "# except IndexError:\n",
    "#     print(\"Please specify names of test data file and of outfile for labels.\")\n",
    "#     sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../data/train.json.txt\"\n",
    "test_file = \"../data/test-covered.json.txt\"\n",
    "outfile = \"output_predictions.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 1. LOAD TRAINING DATA ALTERED\n",
    "##################################################################################################\n",
    "\n",
    "PairExample = namedtuple('PairExample',\n",
    "    'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "    'left, mention_1, middle, mention_2, right, direction')\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i,line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "\n",
    "        instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "\n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'],snippet['mention_1'],snippet['middle'],\n",
    "                                   snippet['mention_2'],snippet['right'],\n",
    "                                    snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "\n",
    "                data.append(instance_tuple)\n",
    "                labels.append(instance['relation'])\n",
    "                instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "\n",
    "            except:\n",
    "                print(instance)\n",
    "\n",
    "    f.close()\n",
    "    return data,labels\n",
    "\n",
    "train_data, train_labels = load_data(train_file)\n",
    "\n",
    "print('*'*40)\n",
    "print(\"Training data successfully loaded.\")\n",
    "print(\"{} sample in train_data\".format(len(train_data)))\n",
    "print('*'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 1.1 LOAD TEST DATA\n",
    "##################################################################################################\n",
    "\n",
    "def load_test_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i,line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "        if i==0:\n",
    "            if verbose:\n",
    "                print('json example:')\n",
    "                print(instance)\n",
    "        #'relation, entity_1, entity_2, snippet' fileds for each example\n",
    "        #'left, mention_1, middle, mention_2, right, direction' for each snippet\n",
    "        instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'],snippet['mention_1'],snippet['middle'],\n",
    "                                   snippet['mention_2'],snippet['right'],\n",
    "                                    snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "            except:\n",
    "                print(instance)\n",
    "        if i==0:\n",
    "            if verbose:\n",
    "                print('\\nexample transformed as a named tuple:')\n",
    "                print(instance_tuple)\n",
    "        data.append(instance_tuple)\n",
    "        labels.append(instance['relation'])\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)\n",
    "print('*'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 2. EXTRACT FEATURES and BUILD CLASSIFIER\n",
    "##################################################################################################\n",
    "\n",
    "def SelectContext(data, verbose=True):\n",
    "    \"\"\"BOW feature extraction\"\"\"\n",
    "    only_context_data = []\n",
    "    for instance in data:\n",
    "\n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            instance_context.append(context)\n",
    "        only_context_data.append(' '.join(instance_context))\n",
    "    if verbose:\n",
    "        print(len(only_context_data))\n",
    "        print(only_context_data[0])\n",
    "        print(only_context_data[0])\n",
    "    return only_context_data\n",
    "\n",
    "# test_feat = SelectContext(train_data[:200])\n",
    "\n",
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    \"\"\"Considers length and words of middle segment\"\"\"\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {'mid_words': '', 'distance': np.inf, 'direction': 0}\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "            if s.direction == 'fwd':\n",
    "                featurized_instance['direction'] = 1\n",
    "            else:\n",
    "                featurized_instance['direction'] = 0\n",
    "\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data\n",
    "\n",
    "# test_feat = ExractSimpleFeatures(train_data[:200])\n",
    "\n",
    "def LengthOfEntities(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'entity1_len': len(instance.entity_1.split(\"_\")),\n",
    "            'entity2_len': len(instance.entity_2.split(\"_\")),\n",
    "            'combined_len': len(instance.entity_1.split(\"_\")) + len(instance.entity_2.split(\"_\"))\n",
    "        }\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data\n",
    "\n",
    "# test_feat = LengthOfEntities(train_data[:200])\n",
    "\n",
    "class SimpleFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ExractSimpleFeatures(X, verbose=False)\n",
    "\n",
    "\n",
    "class EntityLengthFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each isntance for DictVectorizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return LengthOfEntities(X, verbose=False)\n",
    "\n",
    "\n",
    "class BowFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return SelectContext(X, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform labels to numeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "\n",
    "length_pipe = make_pipeline(EntityLengthFeaturizer(LengthOfEntities), DictVectorizer())\n",
    "\n",
    "bow_pipe = make_pipeline(BowFeaturizer(SelectContext), CountVectorizer(ngram_range=(1,3)))\n",
    "\n",
    "simple_pipe = make_pipeline(SimpleFeaturizer(ExractSimpleFeatures), DictVectorizer())\n",
    "\n",
    "clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "    ('length_pipeline', length_pipe),\n",
    "    ('bow_pipeline', bow_pipe),\n",
    "    ('simple_pipeline', simple_pipe)]),\n",
    "    LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 3. TRAIN CLASSIFIER AND EVALUATE (CV)\n",
    "##################################################################################################\n",
    "\n",
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "\n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    classifier: clf - pipeline with CountVevtorizer and Logistic regression\n",
    "    label_encoder: le - label encoder\n",
    "    X: train data featurized\n",
    "    y: train labels featurized\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0)\n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            #print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "#             print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic\n",
    "\n",
    "\n",
    "evaluateCV(clf, le, train_data, train_labels_featurized)\n",
    "\n",
    "print('*'*40)\n",
    "\n",
    "# A check for the average F1 score\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0)\n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())\n",
    "\n",
    "\n",
    "evaluateCV_check(clf, train_data, train_labels_featurized)\n",
    "\n",
    "print('*'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 4. TEST PREDICTIONS and ANALYSIS\n",
    "##################################################################################################\n",
    "\n",
    "# Fit final model on the full train data\n",
    "clf.fit(train_data, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "test_data, test_labels = load_test_data(test_file, verbose=False)\n",
    "print(\"Test data successfully loaded.\")\n",
    "print(\"{} samples in test_data\".format(len(test_data)))\n",
    "print('*'*40)\n",
    "test_label_predicted = clf.predict(test_data)\n",
    "# print(len(test_label_predicted))\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(\"{} predictions made on test_data\".format(len(test_label_predicted_decoded)))\n",
    "print('*'*40)\n",
    "\n",
    "# print(test_label_predicted_decoded[:2])\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as f:\n",
    "    for label in test_label_predicted_decoded:\n",
    "        f.write(label+'\\n')\n",
    "\n",
    "print(\"Predictions written to file {}\".format(outfile))\n",
    "print('*'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature analisys - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier, label_encoder, N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['featureunion'].transformer_list[1][1].named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf, le, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
