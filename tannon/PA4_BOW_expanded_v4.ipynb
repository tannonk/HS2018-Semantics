{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this script sets a baseline for relation extraction using frequency-based BOW model\n",
    "\n",
    "#### add additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "##### additional imports\n",
    "import networkx as nx\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 1. LOAD DATA\n",
    "##################################################################################################\n",
    "\n",
    "PairExample = namedtuple('PairExample',\n",
    "    'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "    'left, mention_1, middle, mention_2, right, direction')\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i,line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "\n",
    "        instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "        \n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'],snippet['mention_1'],snippet['middle'],\n",
    "                                   snippet['mention_2'],snippet['right'],\n",
    "                                    snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "                \n",
    "                data.append(instance_tuple)\n",
    "                labels.append(instance['relation'])\n",
    "                instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "                \n",
    "            except:\n",
    "                print(instance)\n",
    "\n",
    "\n",
    "    return data,labels\n",
    "    \n",
    "train_data, train_labels = load_data('../data/train.json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42338\n",
      "42338\n"
     ]
    }
   ],
   "source": [
    "# for i in train_data[:10]:\n",
    "#     print(i)\n",
    "#     print()\n",
    "\n",
    "print(len(train_labels))\n",
    "print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics:\n",
      "                                rel_examples\n",
      "relation               examples /all_examples\n",
      "--------               --------    -------\n",
      "has_spouse                13061       0.31\n",
      "author                    13113       0.31\n",
      "NO_REL                     3068       0.07\n",
      "capital                    9427       0.22\n",
      "worked_at                  3669       0.09\n",
      "--------               --------    -------\n",
      "Total                     42338       1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dictionary\n",
      "has_spouse Judy_Garland David_Rose\n",
      "author Charlie_and_the_Chocolate_Factory Roald_Dahl\n",
      "NO_REL Sichuan Tibet\n",
      "capital Andalusia Seville\n",
      "worked_at Carl-Henric_Svanberg Ericsson\n"
     ]
    }
   ],
   "source": [
    "# check that each entity pair is assigned only one relation\n",
    "pair_dict={}\n",
    "rel_dict={}\n",
    "for example, label in zip(train_data,train_labels):\n",
    "    if (example.entity_1,example.entity_2) not in pair_dict.keys():\n",
    "        pair_dict[(example.entity_1,example.entity_2)] = [label]\n",
    "        \n",
    "    else:\n",
    "        pair_dict[(example.entity_1,example.entity_2)].append(label)\n",
    "#         print(example.entity_1,example.entity_2,label)\n",
    "    if label not in rel_dict.keys():\n",
    "        rel_dict[label] = [example]\n",
    "    else:\n",
    "        rel_dict[label].append(example)\n",
    "print(\"Done building dictionary\")  \n",
    "    \n",
    "# example for each relation\n",
    "for rel in rel_dict.keys():\n",
    "    ex = rel_dict[rel][0]\n",
    "    print(rel,ex.entity_1,ex.entity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to reconstruct full context\n",
    "\n",
    "# ex = train_data[0]\n",
    "# print(ex)\n",
    "# print(\"\\n full context:\")\n",
    "# s = ex.snippet[0]\n",
    "# print(' '.join((s.left, s.mention_1, s.middle, s.mention_2, s.right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rebuild_text(ex):\n",
    "#     rebuilt_ex = []\n",
    "#     for s in ex.snippet:\n",
    "#         text = ' '.join((s.left, s.mention_1, s.middle, s.mention_2, s.right))\n",
    "#         rebuilt_ex.append(text)\n",
    "#     return rebuilt_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_text_from_snippet(s):\n",
    "#     text = ' '.join((s.left, s.mention_1, s.middle, s.mention_2, s.right))\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rebuild_corpus(data):\n",
    "#     corpus = []\n",
    "#     for ex in data:\n",
    "#         corpus.append(rebuild_text(ex)) \n",
    "#     return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_key_sents(data):\n",
    "#     key_sents = []\n",
    "#     for ex in data:\n",
    "#         m1 = ex.snippet[0].mention_1\n",
    "#         m2 = ex.snippet[0].mention_2\n",
    "#         text = build_text_from_snippet(ex.snippet[0])\n",
    "#         doc = nlp(text)\n",
    "#         for sent in doc.sents:\n",
    "# #             print(sent)\n",
    "#             if m1 in sent.string and m2 in sent.string:\n",
    "#                 key_sents.append(sent)\n",
    "#                 continue\n",
    "                \n",
    "#     return key_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_sents = extract_key_sents(train_data[:100])\n",
    "# print(type(key_sents[0]))\n",
    "# for sent in key_sents:\n",
    "#     for chunk in sent.noun_chunks:\n",
    "#         print(chunk.label_, chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "#           chunk.root.head.text)\n",
    "#     for token in sent: \n",
    "#         print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "#               [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_tokens(doc):\n",
    "    tagged_ex = []\n",
    "    \n",
    "    for w in doc:\n",
    "        if w.orth_ == \"m_1\" or w.orth_ == \"m_2\":\n",
    "            tagged_ex.append(w.orth_)\n",
    "        else:\n",
    "            tagged_ex.append(w.pos_)\n",
    "            \n",
    "    tagged_ex = \" \".join(tagged_ex)\n",
    "    \n",
    "    return tagged_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    lemmas = []\n",
    "    \n",
    "    for w in doc:\n",
    "        if w.lemma_ == \"-PRON-\" or w.orth_ == \"m_1\" or w.orth_ == \"m_2\":\n",
    "            lemmas.append(w.orth_)\n",
    "        else:\n",
    "            lemmas.append(w.lemma_)\n",
    "    \n",
    "    lemmas = \" \".join(lemmas)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 2.1 PERFORM NLP ON CORPUS DATA\n",
    "##################################################################################################\n",
    "\n",
    "def perform_nlp(data, verbose=True):\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"{} instances in data\".format(len(data)))\n",
    "        print(\"first instance looks like {}\".format(data[0]))\n",
    "        \n",
    "    c = 0\n",
    "    docs = []\n",
    "    for instance in data:\n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = nlp(s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right)\n",
    "            instance_context.append(context)\n",
    "        docs.append(instance_context)\n",
    "        c += 1\n",
    "    \n",
    "        if verbose:\n",
    "            if c % 1000 == 0:\n",
    "                print(\"{} instances processed.\".format(c))\n",
    "        \n",
    "    if verbose:\n",
    "        print(len(docs))\n",
    "        print(docs[0])\n",
    "        print(\"Structure of context data is: {}-{}-{}\".format(type(docs),\n",
    "                                                              type(docs[0]),\n",
    "                                                              type(docs[0][0])\n",
    "                                                             )\n",
    "             )\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectContext(data, verbose=True):\n",
    "    \"\"\"BOW feature extraction\"\"\"\n",
    "    only_context_data = []\n",
    "    for instance in data:\n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            instance_context.append(context)\n",
    "        only_context_data.append(' '.join(instance_context))\n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(only_context_data))\n",
    "        print(data[0])\n",
    "        print(only_context_data[0])\n",
    "    return only_context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {'mid_words':'', 'distance':np.inf, 'mid_pos': ''}\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "                featurized_instance['mid_pos'] = ' '.join([w.pos_ for w in nlp(s.middle)])\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(featurized_data))\n",
    "        print(data[0])\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LengthOfEntities(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'entity1_len': len(instance.entity_1.split(\"_\")),\n",
    "            'entity2_len': len(instance.entity_2.split(\"_\")),\n",
    "            'combined_len': len(instance.entity_1.split(\"_\")) + len(instance.entity_2.split(\"_\"))\n",
    "        }\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(featurized_data))\n",
    "        print(data[0])\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindDepPath(data, verbose=True):\n",
    "    only_context_data = []\n",
    "    for instance in data:\n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "#             print(context)\n",
    "            document = nlp(context)\n",
    "            edges = []\n",
    "            for token in document:\n",
    "                # FYI https://spacy.io/docs/api/token\n",
    "                for child in token.children:\n",
    "                    edges.append(('{0}-{1}'.format(token.lower_,token.i),\n",
    "                                  '{0}-{1}'.format(child.lower_,child.i)))\n",
    "\n",
    "            graph = nx.Graph(edges)\n",
    "#             print(graph)\n",
    "            for w in graph:\n",
    "#                 print(w)\n",
    "                if \"m_1\" in w:\n",
    "                    s = w\n",
    "                if \"m_2\" in w:\n",
    "                    t = w\n",
    "            \n",
    "#             print(\"s: \", len(s), \"\\t\", \"t: \", len(t))\n",
    "#             if len(s) > 7 or len(t) > 7:\n",
    "#                 pass\n",
    "#             else:\n",
    "            try:\n",
    "                instance_context.append(nx.shortest_path_length(graph, source=s, target=t))\n",
    "            except nx.NetworkXNoPath:\n",
    "                instance_context.append(0)\n",
    "            except nx.NodeNotFound:\n",
    "                pass\n",
    "        try:                                \n",
    "            only_context_data.append(sum(instance_context)/len(instance_context))\n",
    "        except ZeroDivisionError:\n",
    "            only_context_data.append(0)\n",
    "            \n",
    "    if verbose:\n",
    "        print(len(data))\n",
    "        print(len(only_context_data))\n",
    "        print(data[0])\n",
    "        print(only_context_data[0])\n",
    "\n",
    "    return only_context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feat = LengthOfEntities(train_data)\n",
    "# test_feat = ExractSimpleFeatures(train_data[:10])\n",
    "# \n",
    "# test_feat = FindDepPath(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_feat))\n",
    "# print(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SelectTaggedContext(data, verbose=True):\n",
    "    \n",
    "#     processed_data = perform_nlp(data)\n",
    "    \n",
    "#     tagged_data = []\n",
    "#     for processed_instance in processed_data:\n",
    "#         instance_tags = []\n",
    "#         for doc in processed_instance:  \n",
    "#             tags = tag_tokens(doc)\n",
    "#             instance_tags.append(tags)\n",
    "#         tagged_data.append(' '.join(instance_tags))\n",
    "#     if verbose:\n",
    "#         print(len(processed_data))\n",
    "#         print(len(tagged_data))\n",
    "#         print(processed_data[0])\n",
    "#         print(tagged_data[0])\n",
    "#     return tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ExractSimpleFeatures(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityLengthFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each isntance for DictVectorizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return LengthOfEntities(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BowFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return SelectContext(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyPath(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return FindDepPath(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform labels to numeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "\n",
    "# Fit model one vs rest logistic regression    \n",
    "# clf = make_pipeline(DictVectorizer(), LogisticRegression())\n",
    "\n",
    "# clf = make_pipeline(union, LogisticRegression())\n",
    "\n",
    "# length_pipe = Pipeline([\n",
    "#   ('ent_length', EntityLengthFeaturizer(LengthOfEntities)),\n",
    "#   ('ent_length_vectorize', DictVectorizer())\n",
    "#   ])\n",
    "\n",
    "# bow_pipe = Pipeline([\n",
    "#   ('context_data', BowFeaturizer(SelectContext)),\n",
    "#   ('context_data_vectorize', CountVectorizer())\n",
    "#   ])\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('feat_union', FeatureUnion(transformer_list=[\n",
    "#           ('length_pipeline', length_pipe),\n",
    "#           ('bow_pipeline', bow_pipe)\n",
    "#           ])),\n",
    "#     ('classify', LogisticRegression())\n",
    "#     ])\n",
    "\n",
    "\n",
    "length_pipe = make_pipeline(EntityLengthFeaturizer(LengthOfEntities), DictVectorizer())\n",
    "\n",
    "bow_pipe = make_pipeline(BowFeaturizer(SelectContext), CountVectorizer(ngram_range=(1,3)))\n",
    "# bow_pipe = make_pipeline(BowFeaturizer(SelectContext), CountVectorizer())\n",
    "\n",
    "simple_pipe = make_pipeline(SimpleFeaturizer(ExractSimpleFeatures), DictVectorizer())\n",
    "\n",
    "dep_pipe = make_pipeline(DependencyPath(FindDepPath))\n",
    "\n",
    "clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "    ('length_pipeline', length_pipe),\n",
    "    ('bow_pipeline', bow_pipe),\n",
    "    ('simple_pipeline', simple_pipe),\n",
    "    ('dependency_pipeline', DependencyPath(FindDepPath))]),\n",
    "    LogisticRegression())\n",
    "\n",
    "# clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "#     ('length_pipeline', length_pipe),\n",
    "#     ('bow_pipeline', bow_pipe),\n",
    "#     ('simple_pipeline', simple_pipe)]),\n",
    "#     LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 3. TRAIN CLASSIFIER AND EVALUATE (CV)\n",
    "##################################################################################################\n",
    "\n",
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "    \n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    classifier: clf - pipeline with CountVevtorizer and Logistic regression\n",
    "    label_encoder: le - label encoder\n",
    "    X: train data featurized\n",
    "    y: train labels featurized\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "#         print(rel)\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            #print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "#             print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.782      0.406      0.660       3068\n",
      "author                    0.933      0.971      0.941      13113\n",
      "capital                   0.938      0.973      0.945       9427\n",
      "has_spouse                0.912      0.978      0.925      13061\n",
      "worked_at                 0.907      0.820      0.888       3669\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.895      0.830      0.872      42338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8716350652593686"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateCV(clf, le, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A check for the average F1 score\n",
    "\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.78319178 0.77791582 0.78375181 0.78223485 0.78230726]\n",
      "Mean cv score (StratifiedKFold):  0.7818803012927733\n"
     ]
    }
   ],
   "source": [
    "evaluateCV_check(clf, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840\n",
      "1840\n",
      "1840\n",
      "['capital' 'NO_REL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# 4. TEST PREDICTIONS and ANALYSIS\n",
    "##################################################################################################\n",
    "\n",
    "# Fit final model on the full train data\n",
    "clf.fit(train_data, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "test_data, test_labels = load_data('../data/test-covered.json.txt', verbose=False)\n",
    "print(len(test_labels))\n",
    "# test_data_featurized = SelectContext(test_data, verbose=False)\n",
    "test_label_predicted = clf.predict(test_data)\n",
    "print(len(test_label_predicted))\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(len(test_label_predicted_decoded))\n",
    "print(test_label_predicted_decoded[:2])\n",
    "f = open(\"outputs/test_labels.txt\", 'w', encoding=\"utf-8\")\n",
    "for label in test_label_predicted_decoded:\n",
    "    f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature analisys - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier,label_encoder,N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf,le,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
