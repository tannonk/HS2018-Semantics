{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this script sets a baseline for relation extraction using frequency-based BOW model\n",
    "\n",
    "#### add additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "##### additional imports\n",
    "import networkx as nx\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 1. LOAD DATA\n",
    "##################################################################################################\n",
    "\n",
    "PairExample = namedtuple('PairExample',\n",
    "    'entity_1, entity_2, snippet')\n",
    "Snippet = namedtuple('Snippet',\n",
    "    'left, mention_1, middle, mention_2, right, direction')\n",
    "def load_data(file, verbose=True):\n",
    "    f = open(file,'r', encoding='utf-8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i,line in enumerate(f):\n",
    "        instance = json.loads(line)\n",
    "\n",
    "        instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "        \n",
    "        for snippet in instance['snippet']:\n",
    "            try:\n",
    "                snippet_tuple = Snippet(snippet['left'],snippet['mention_1'],snippet['middle'],\n",
    "                                   snippet['mention_2'],snippet['right'],\n",
    "                                    snippet['direction'])\n",
    "                instance_tuple.snippet.append(snippet_tuple)\n",
    "                \n",
    "                data.append(instance_tuple)\n",
    "                labels.append(instance['relation'])\n",
    "                instance_tuple = PairExample(instance['entity_1'],instance['entity_2'],[])\n",
    "                \n",
    "            except:\n",
    "                print(instance)\n",
    "\n",
    "\n",
    "    return data,labels\n",
    "    \n",
    "train_data, train_labels = load_data('../data/train.json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_data[:10]:\n",
    "#     print(i)\n",
    "#     print()\n",
    "\n",
    "# print(len(train_labels))\n",
    "# print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics:\n",
      "                                rel_examples\n",
      "relation               examples /all_examples\n",
      "--------               --------    -------\n",
      "has_spouse                13061       0.31\n",
      "author                    13113       0.31\n",
      "NO_REL                     3068       0.07\n",
      "capital                    9427       0.22\n",
      "worked_at                  3669       0.09\n",
      "--------               --------    -------\n",
      "Total                     42338       1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics over relations\n",
    "def print_stats(labels):\n",
    "    labels_counts = Counter(labels)\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('', '', 'rel_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('relation', 'examples', '/all_examples'))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    for k,v in labels_counts.items():\n",
    "        print('{:20s} {:10d} {:10.2f}'.format(k, v, v /len(labels)))\n",
    "    print('{:20s} {:>10s} {:>10s}'.format('--------', '--------', '-------'))\n",
    "    print('{:20s} {:10d} {:10.2f}'.format('Total', len(labels), len(labels) /len(labels)))\n",
    "\n",
    "print('Train set statistics:')\n",
    "print_stats(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dictionary\n",
      "has_spouse Judy_Garland David_Rose\n",
      "author Charlie_and_the_Chocolate_Factory Roald_Dahl\n",
      "NO_REL Sichuan Tibet\n",
      "capital Andalusia Seville\n",
      "worked_at Carl-Henric_Svanberg Ericsson\n"
     ]
    }
   ],
   "source": [
    "# check that each entity pair is assigned only one relation\n",
    "pair_dict={}\n",
    "rel_dict={}\n",
    "for example, label in zip(train_data,train_labels):\n",
    "    if (example.entity_1,example.entity_2) not in pair_dict.keys():\n",
    "        pair_dict[(example.entity_1,example.entity_2)] = [label]\n",
    "        \n",
    "    else:\n",
    "        pair_dict[(example.entity_1,example.entity_2)].append(label)\n",
    "#         print(example.entity_1,example.entity_2,label)\n",
    "    if label not in rel_dict.keys():\n",
    "        rel_dict[label] = [example]\n",
    "    else:\n",
    "        rel_dict[label].append(example)\n",
    "print(\"Done building dictionary\")  \n",
    "    \n",
    "# example for each relation\n",
    "for rel in rel_dict.keys():\n",
    "    ex = rel_dict[rel][0]\n",
    "    print(rel,ex.entity_1,ex.entity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectContext(data, verbose=True):\n",
    "    \"\"\"BOW feature extraction\"\"\"\n",
    "    only_context_data = []\n",
    "    for instance in data:\n",
    "        \n",
    "        instance_context = []\n",
    "        for s in instance.snippet:\n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            instance_context.append(context)\n",
    "        only_context_data.append(' '.join(instance_context))\n",
    "    if verbose:\n",
    "        print(len(only_context_data))\n",
    "        print(only_context_data[0])\n",
    "        print(only_context_data[0])\n",
    "    return only_context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old m_1 while she was engaged to composer m_2 . Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair\n",
      "thirty and his life and career were riding high . In 1941 , shortly after the death of his father , Mercer began an intense affair with nineteen-year-old m_1 while she was engaged to composer m_2 . Garland married Rose to temporarily stop the affair , but the effect on Mercer lingered , adding to the emotional depth of his lyrics . Their affair\n"
     ]
    }
   ],
   "source": [
    "test_feat = SelectContext(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExractSimpleFeatures(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {'mid_words': '', 'distance': np.inf}\n",
    "        for s in instance.snippet:\n",
    "            if len(s.middle.split()) < featurized_instance['distance']:\n",
    "                featurized_instance['mid_words'] = s.middle\n",
    "                featurized_instance['distance'] = len(s.middle.split())\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'mid_words': 'while she was engaged to composer', 'distance': 6}\n",
      "{'mid_words': 'by', 'distance': 1}\n"
     ]
    }
   ],
   "source": [
    "test_feat = ExractSimpleFeatures(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LengthOfEntities(data, verbose=True):\n",
    "    featurized_data = []\n",
    "    for instance in data:\n",
    "        featurized_instance = {\n",
    "            'entity1_len': len(instance.entity_1.split(\"_\")),\n",
    "            'entity2_len': len(instance.entity_2.split(\"_\")),\n",
    "            'combined_len': len(instance.entity_1.split(\"_\")) + len(instance.entity_2.split(\"_\"))\n",
    "        }\n",
    "        featurized_data.append(featurized_instance)\n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "    return featurized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'entity1_len': 2, 'entity2_len': 2, 'combined_len': 4}\n",
      "{'entity1_len': 5, 'entity2_len': 2, 'combined_len': 7}\n"
     ]
    }
   ],
   "source": [
    "test_feat = LengthOfEntities(train_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UseNLP(data, verbose=True, status=True):\n",
    "    featurized_data = []\n",
    "    c = 0\n",
    "    for instance in data:\n",
    "        \n",
    "        featurized_instance = {'tagged_context_1': '', 'tagged_context_2': '', 'path_length': 0}\n",
    "        \n",
    "        for s in instance.snippet:\n",
    "                        \n",
    "            context = s.left + \" m_1 \" + s.middle + \" m_2 \" + s.right\n",
    "            \n",
    "            document = nlp(context) # spacy pipeline\n",
    "            \n",
    "            tagged_context_1 = []\n",
    "            tagged_context_2 = []\n",
    "            \n",
    "            for i, w in enumerate(document):\n",
    "                if w.orth_ == \"m_1\":\n",
    "                    window_1 = document[i-3:i+4]\n",
    "                    for e in window_1:\n",
    "                        if e.orth_ == \"m_1\" or e.orth_ == \"m_2\":\n",
    "                            tagged_context_1.append(\"MENTION\")\n",
    "                        else:\n",
    "                            tagged_context_1.append(e.pos_)\n",
    "                \n",
    "                if w.orth_ == \"m_2\":\n",
    "                    window_2 = document[i-3:i+4]\n",
    "                    if window_2:\n",
    "                        for e in window_2:\n",
    "                            if e.orth_ == \"m_1\" or e.orth_ == \"m_2\":\n",
    "                                tagged_context_2.append(\"MENTION\")\n",
    "                            else:\n",
    "                                tagged_context_2.append(e.pos_)\n",
    "            \n",
    "            featurized_instance['tagged_context_1'] = ' '.join(tagged_context_1)\n",
    "            featurized_instance['tagged_context_2'] = ' '.join(tagged_context_2)\n",
    "            \n",
    "            edges = []\n",
    "            for w in document: # FYI https://spacy.io/docs/api/token\n",
    "                for child in w.children:\n",
    "                    edges.append(('{0}-{1}'.format(w.lower_, w.i),\n",
    "                                  '{0}-{1}'.format(child.lower_, child.i)))\n",
    "\n",
    "            graph = nx.Graph(edges)\n",
    "#             print(graph)\n",
    "            for w in graph:\n",
    "#                 print(w)\n",
    "                if \"m_1\" in w:\n",
    "                    s = w\n",
    "                if \"m_2\" in w:\n",
    "                    t = w\n",
    "            \n",
    "            try:\n",
    "                featurized_instance['path_length'] = nx.shortest_path_length(graph, source=s, target=t)\n",
    "            except nx.NetworkXNoPath: # unrelated?\n",
    "                featurized_instance['path_length'] = 0\n",
    "            except nx.NodeNotFound: # problem with mention\n",
    "                featurized_instance['path_length'] = 0.5\n",
    "\n",
    "        featurized_data.append(featurized_instance)\n",
    "        c = 0\n",
    "        if status:\n",
    "            if c % 5000 == 0:\n",
    "                print(\"{} instances processed.\".format(c))\n",
    "                \n",
    "    if verbose:\n",
    "        print(len(featurized_data))\n",
    "        print(featurized_data[0])\n",
    "        print(featurized_data[1])\n",
    "            \n",
    "    return featurized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'tagged_context_1': 'NOUN PUNCT ADJ MENTION ADP PRON VERB', 'tagged_context_2': 'VERB ADP NOUN MENTION PUNCT PROPN VERB', 'path_length': 5}\n",
      "{'tagged_context_1': 'ADP DET NUM MENTION ADP MENTION PUNCT', 'tagged_context_2': 'NUM MENTION ADP MENTION PUNCT VERB ADP', 'path_length': 4}\n"
     ]
    }
   ],
   "source": [
    "test_feat = UseNLP(train_data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ExractSimpleFeatures(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityLengthFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each isntance for DictVectorizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return LengthOfEntities(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BowFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return SelectContext(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyPath(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"BOW featurizer\"\"\"\n",
    "    def __init__(self, featurizer):\n",
    "        self.featurizers = featurizer\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return UseNLP(X, verbose=False, status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform labels to numeric values\n",
    "le = LabelEncoder()\n",
    "train_labels_featurized = le.fit_transform(train_labels)\n",
    "\n",
    "length_pipe = make_pipeline(EntityLengthFeaturizer(LengthOfEntities), DictVectorizer())\n",
    "\n",
    "bow_pipe = make_pipeline(BowFeaturizer(SelectContext), CountVectorizer(ngram_range=(1,3)))\n",
    "\n",
    "simple_pipe = make_pipeline(SimpleFeaturizer(ExractSimpleFeatures), DictVectorizer())\n",
    "\n",
    "syntax_pipe = make_pipeline(DependencyPath(FindDepPath), DictVectorizer())\n",
    "\n",
    "clf = make_pipeline(FeatureUnion(transformer_list=[\n",
    "    ('length_pipeline', length_pipe),\n",
    "    ('bow_pipeline', bow_pipe),\n",
    "    ('simple_pipeline', simple_pipe),\n",
    "    ('syntax_pipeline', syntax_pipe)]),\n",
    "    LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# 3. TRAIN CLASSIFIER AND EVALUATE (CV)\n",
    "##################################################################################################\n",
    "\n",
    "def print_statistics_header():\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        'relation', 'precision', 'recall', 'f-score', 'support'))\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "\n",
    "def print_statistics_row(rel, result):\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format(rel, *result))\n",
    "\n",
    "def print_statistics_footer(avg_result):\n",
    "    print('{:20s} {:>10s} {:>10s} {:>10s} {:>10s}'.format(\n",
    "        '-' * 18, '-' * 9, '-' * 9, '-' * 9, '-' * 9))\n",
    "    print('{:20s} {:10.3f} {:10.3f} {:10.3f} {:10d}'.format('macro-average', *avg_result))\n",
    "\n",
    "def macro_average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results.values()]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results.values()]))\n",
    "    return avg_result\n",
    "\n",
    "def average_results(results):\n",
    "    avg_result = [np.average([r[i] for r in results]) for i in range(3)]\n",
    "    avg_result.append(np.sum([r[3] for r in results]))\n",
    "    return avg_result\n",
    "    \n",
    "def evaluateCV(classifier, label_encoder, X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    classifier: clf - pipeline with CountVevtorizer and Logistic regression\n",
    "    label_encoder: le - label encoder\n",
    "    X: train data featurized\n",
    "    y: train labels featurized\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for rel in le.classes_:\n",
    "#         print(rel)\n",
    "        results[rel] = []\n",
    "    if verbose:\n",
    "        print_statistics_header()\n",
    "        kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred_labels = classifier.predict(X_test)\n",
    "            stats = precision_recall_fscore_support(y_test, pred_labels, beta=0.5)\n",
    "            #print(stats)\n",
    "            for rel in label_encoder.classes_:\n",
    "                rel_id = label_encoder.transform([rel])[0]\n",
    "#             print(rel_id,rel)\n",
    "                stats_rel = [stat[rel_id] for stat in stats]\n",
    "                results[rel].append(stats_rel)\n",
    "        for rel in label_encoder.classes_:\n",
    "            results[rel] = average_results(results[rel])\n",
    "            if verbose:\n",
    "                print_statistics_row(rel, results[rel])\n",
    "    avg_result = macro_average_results(results)\n",
    "    if verbose:\n",
    "        print_statistics_footer(avg_result)\n",
    "    return avg_result[2]  # return f_0.5 score as summary statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "33868\n",
      "{'tagged_context_1': 'NOUN PUNCT ADJ MENTION ADP PRON VERB', 'tagged_context_2': 'VERB ADP NOUN MENTION PUNCT PROPN VERB', 'path_length': 5}\n",
      "{'tagged_context_1': 'ADP DET NUM MENTION ADP MENTION PUNCT', 'tagged_context_2': 'NUM MENTION ADP MENTION PUNCT VERB ADP', 'path_length': 4}\n",
      "8470\n",
      "{'tagged_context_1': 'ADJ ADP DET MENTION NOUN ADP NOUN', 'tagged_context_2': 'ADP NOUN VERB MENTION CCONJ ADJ NOUN', 'path_length': 5}\n",
      "{'tagged_context_1': 'PUNCT VERB ADP MENTION PUNCT VERB ADP', 'tagged_context_2': 'ADP ADJ NOUN MENTION PUNCT PRON VERB', 'path_length': 4}\n",
      "33869\n",
      "{'tagged_context_1': 'NOUN PUNCT ADJ MENTION ADP PRON VERB', 'tagged_context_2': 'VERB ADP NOUN MENTION PUNCT PROPN VERB', 'path_length': 5}\n",
      "{'tagged_context_1': 'ADP DET NUM MENTION ADP MENTION PUNCT', 'tagged_context_2': 'NUM MENTION ADP MENTION PUNCT VERB ADP', 'path_length': 4}\n",
      "8469\n",
      "{'tagged_context_1': 'NOUN ADJ ADP MENTION ADP MENTION CCONJ', 'tagged_context_2': 'ADP MENTION ADP MENTION CCONJ PROPN PROPN', 'path_length': 6}\n",
      "{'tagged_context_1': 'VERB VERB ADP MENTION PART NUM NOUN', 'tagged_context_2': 'PART NUM NOUN MENTION PUNCT CCONJ NUM', 'path_length': 2}\n",
      "33870\n",
      "{'tagged_context_1': 'NOUN PUNCT ADJ MENTION ADP PRON VERB', 'tagged_context_2': 'VERB ADP NOUN MENTION PUNCT PROPN VERB', 'path_length': 5}\n",
      "{'tagged_context_1': 'ADP DET NUM MENTION ADP MENTION PUNCT', 'tagged_context_2': 'NUM MENTION ADP MENTION PUNCT VERB ADP', 'path_length': 4}\n",
      "8468\n",
      "{'tagged_context_1': 'PUNCT VERB ADP MENTION ADP MENTION PUNCT', 'tagged_context_2': 'ADP MENTION ADP MENTION PUNCT PUNCT PRON', 'path_length': 4}\n",
      "{'tagged_context_1': 'PART NOUN ADP MENTION PART MENTION PUNCT', 'tagged_context_2': 'ADP MENTION PART MENTION PUNCT PUNCT NUM', 'path_length': 1}\n",
      "33872\n",
      "{'tagged_context_1': 'NOUN PUNCT ADJ MENTION ADP PRON VERB', 'tagged_context_2': 'VERB ADP NOUN MENTION PUNCT PROPN VERB', 'path_length': 5}\n",
      "{'tagged_context_1': 'ADP DET NUM MENTION ADP MENTION PUNCT', 'tagged_context_2': 'NUM MENTION ADP MENTION PUNCT VERB ADP', 'path_length': 4}\n",
      "8466\n",
      "{'tagged_context_1': 'NOUN PUNCT PUNCT MENTION PUNCT ADP MENTION', 'tagged_context_2': 'MENTION PUNCT ADP MENTION PUNCT ADP DET', 'path_length': 2}\n",
      "{'tagged_context_1': 'DET NOUN ADP MENTION PUNCT ADJ MENTION', 'tagged_context_2': 'MENTION PUNCT ADJ MENTION VERB ADV VERB', 'path_length': 2}\n",
      "33873\n",
      "{'tagged_context_1': 'PUNCT VERB ADP MENTION ADP MENTION PUNCT', 'tagged_context_2': 'ADP MENTION ADP MENTION PUNCT PUNCT PRON', 'path_length': 4}\n",
      "{'tagged_context_1': 'NOUN PUNCT PUNCT MENTION PUNCT ADP MENTION', 'tagged_context_2': 'MENTION PUNCT ADP MENTION PUNCT ADP DET', 'path_length': 2}\n",
      "8465\n",
      "{'tagged_context_1': 'NOUN PUNCT ADJ MENTION ADP PRON VERB', 'tagged_context_2': 'VERB ADP NOUN MENTION PUNCT PROPN VERB', 'path_length': 5}\n",
      "{'tagged_context_1': 'ADP DET NUM MENTION ADP MENTION PUNCT', 'tagged_context_2': 'NUM MENTION ADP MENTION PUNCT VERB ADP', 'path_length': 4}\n",
      "NO_REL                    0.786      0.411      0.665       3068\n",
      "author                    0.933      0.972      0.940      13113\n",
      "capital                   0.940      0.973      0.946       9427\n",
      "has_spouse                0.911      0.977      0.924      13061\n",
      "worked_at                 0.905      0.817      0.886       3669\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.895      0.830      0.872      42338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8721445323326972"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateCV(clf, le, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A check for the average F1 score\n",
    "\n",
    "f_scorer = make_scorer(fbeta_score, beta=0.5, average='macro')\n",
    "\n",
    "def evaluateCV_check(classifier, X, y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) \n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold, scoring = f_scorer)\n",
    "    print(\"\\nCross-validation scores (StratifiedKFold): \", scores)\n",
    "    print(\"Mean cv score (StratifiedKFold): \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.78319178 0.77791582 0.78375181 0.78223485 0.78230726]\n",
      "Mean cv score (StratifiedKFold):  0.7818803012927733\n"
     ]
    }
   ],
   "source": [
    "evaluateCV_check(clf, train_data, train_labels_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840\n",
      "1840\n",
      "1840\n",
      "['capital' 'NO_REL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# 4. TEST PREDICTIONS and ANALYSIS\n",
    "##################################################################################################\n",
    "\n",
    "# Fit final model on the full train data\n",
    "clf.fit(train_data, train_labels_featurized)\n",
    "\n",
    "# Predict on test set\n",
    "test_data, test_labels = load_data('../data/test-covered.json.txt', verbose=False)\n",
    "print(len(test_labels))\n",
    "# test_data_featurized = SelectContext(test_data, verbose=False)\n",
    "test_label_predicted = clf.predict(test_data)\n",
    "print(len(test_label_predicted))\n",
    "# Deprecation warning explained: https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "test_label_predicted_decoded = le.inverse_transform(test_label_predicted)\n",
    "print(len(test_label_predicted_decoded))\n",
    "print(test_label_predicted_decoded[:2])\n",
    "f = open(\"outputs/test_labels.txt\", 'w', encoding=\"utf-8\")\n",
    "for label in test_label_predicted_decoded:\n",
    "    f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature analisys - print N most informative\n",
    "# !! Make changes in this function when you change the pipleine!!\n",
    "def printNMostInformative(classifier,label_encoder,N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = classifier.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "    coef = classifier.named_steps['logisticregression'].coef_    \n",
    "    print(coef.shape)\n",
    "    for rel in label_encoder.classes_:\n",
    "        rel_id = label_encoder.transform([rel])[0]\n",
    "        coef_rel = coef[rel_id]\n",
    "        coefs_with_fns = sorted(zip(coef_rel, feature_names))\n",
    "        top_features = coefs_with_fns[-N:]\n",
    "        print(\"\\nClass {} best: \".format(rel))\n",
    "        for feat in top_features:\n",
    "            print(feat)        \n",
    "        \n",
    "print(\"Top features used to predict: \")\n",
    "# show the top features\n",
    "printNMostInformative(clf,le,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
